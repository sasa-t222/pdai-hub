# .github/workflows/scrape.yml
name: Daily Link Scraper

on:
  schedule:
    - cron: '0 0 * * *' # Runs daily at 00:00 UTC
  workflow_dispatch: # Allows manual trigger

jobs:
  scrape_data:
    permissions:
      contents: write
    runs-on: ubuntu-latest
    steps:
      - name: â¬‡ï¸ Checkout Repository
        uses: actions/checkout@v4
        
      - name: ğŸ› ï¸ Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: ğŸ“¦ Install Dependencies
        run: npm install

      - name: âš™ï¸ Run Scraper & Validator Script
        run: node scrape.js
        
      - name: ğŸ’¾ Commit and Push Updated Data
        # This commits the changes made to the JSON file back to the repo
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "ğŸ¤– [Actions] Auto-updated validated links"
          file_pattern: "public/links.json" # Important: must match the path in scrape.js
